# Base PPO-oriented profile template for rust_rl.
# This file is not the canonical source of runtime defaults.
# Runtime defaults are defined in src/config.rs.
# Precedence order at runtime is:
#   built-in defaults < values in this file < explicit CLI flags
#
# Shared schema note:
# - canonical section name is `training_core`
# - parser also accepts legacy alias `ppo_core` for compatibility

environment:
  # rustpool task id (examples: "BinPack-v0", "Maze-v0")
  task_id: "BinPack-v0"
  # Number of parallel training environments
  num_envs: 16
  # BinPack-specific max number of items in an instance
  max_items: 20
  # BinPack-specific max number of EMS entries
  max_ems: 40
  # Max steps before an episode is truncated (if used by env)
  max_episode_steps: 20

training_core:
  # Trajectory horizon T per environment per PPO update
  rollout_length: 10
  # Total PPO updates
  num_updates: 3
  # PPO epochs over each collected rollout buffer
  epochs: 1
  # Number of minibatches per epoch
  num_minibatches: 16
  # Reward discount factor
  gamma: 0.99
  # GAE lambda
  gae_lambda: 0.95

optimization:
  # Learning rate for actor optimizer
  actor_lr: 0.0003
  # Learning rate for critic optimizer
  critic_lr: 0.001
  # Clip global gradient norm at this threshold
  max_grad_norm: 0.5
  # PPO clipping epsilon
  clip_eps: 0.2
  # Entropy regularization coefficient
  ent_coef: 0.01
  # Value function loss coefficient
  vf_coef: 0.5
  # Linearly decay learning rates over num_updates
  decay_learning_rates: true
  # Standardize advantages before policy updates
  standardize_advantages: true
  # Reward scaling factor applied before GAE
  reward_scale: 1.0

architecture:
  # Hidden layer width for model MLPs
  hidden_dim: 16
  # Optional explicit adapter selection: "dense" | "binpack".
  # Set to null to use metadata auto-detection.
  observation_adapter: null
  # Random seed
  seed: 0

evaluation:
  # Run deterministic evaluation every N updates
  eval_interval: 1
  # Number of parallel environments used during evaluation
  num_eval_envs: 100
  # Number of completed episodes to aggregate per eval phase
  num_eval_episodes: 100

hardware:
  # "cuda" or "cpu"
  device_type: "cuda"
  # CUDA device index used in single-process mode
  cuda_device: 1

logging:
  # Base tracing level used when RUST_LOG is not set
  log_level: "info"
  # Keep CubeCL/CUDA backend context logs hidden by default
  backend_logs_visible: false
  # OTLP base endpoint (traces export uses /v1/traces).
  otlp_endpoint: "http://localhost:5000"
  # Optional existing MLflow run id; null triggers auto-create on lead rank.
  mlflow_run_id: null
